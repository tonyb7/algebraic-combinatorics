\section{Bipartite Graphs}
Recall graph is bipartite with biparts \(x,y\) \iff
\[ A(G)=\begin{bmatrix}0 & B \\ B^T & 0\end{bmatrix} \]

\begin{lemma}
Let \(B\) be an \(n\times n\) matrix such that \(B^TB\) has nonzero eigenvalues \(\lambda_1,\cdots,\lambda_r\) (with multiplicities), then the nonzero eigenvalues of 
\[ A=\begin{bmatrix}0 & B \\ B^T & 0\end{bmatrix}\in\R^{(m+n)\times(m+n)} \]
are precisely \( \sqrt{\lambda_1},-\sqrt{\lambda_1},\cdots,\sqrt{\lambda_r},-\sqrt{\lambda_r} \) (with multiplicities).
\end{lemma}
\begin{remark}
The eigenvalues of \(B^TB\) are real (from symmetry) and nonnegative since if \(B^T Bx=\lambda x\) (we assume \(||x||=1\))
\[ \lambda =\lambda x^T x= x^T (\lambda x)= x^T(B^T Bx) =(Bx)^T(Bx)=\langle Bx,Bx\rangle\geq0. \]
\end{remark}
\begin{proof}
Note that
\[ \begin{bmatrix}t I_m & -B \\ -B^T & t I_n\end{bmatrix}\begin{bmatrix} I_m & B \\ 0 & t I_n\end{bmatrix}=\begin{bmatrix}t I_m & 0 \\ -B^T & t^2 I_n-B^TB \end{bmatrix}. \]
Take determinant gives
\[ \phi_A(t) t^n=t^m\phi_{B^TB}(t^2) \]
\end{proof}
\begin{question}
Why does the matrix on RHS have the determinant \(t^m\phi_{B^T B}(t)\)?
Particularly, why is
\[ \det\left(t^2I_n-B^T B\right)=\phi_{B^T B}\left(t^2\right)? \]
\end{question}
\begin{answer}
By definition, $\phi_{B^T B}(x)=\det(x I_n-B^T B)$. Therefore, $\phi_{B^T B}(t^2)=\det(t^2 I_n - B^T B)$
\end{answer}
% Thanks!

\begin{example}
Let \(K_{m,n}\) be the complete bipartite graph with biparts of size \(m\) and \(n\) and all possible edges between them, then
\[ A(K_{m,n})=\begin{bmatrix}0 & B \\ B^T & 0\end{bmatrix} \]
where \(B\) is an \(m\times n\) all-one matrix. We have
\[ \underbrace{B^T B}_{n\times n} = m J_n \]
where \(J_n\) is the \(n\times n\) all-one matrix.
Recall that \(J_n\) has exactly one nonzero eigenvalues namely \(n\), so the eigenvalues of \(K_{m,n}\) are \(\sqrt{mn},-\sqrt{mn}\) and 0 (multiplicity \(m+n-2\)).
\end{example}

\begin{example}
Let \(C_{2n}\) be a bipartite graph with adjacency matrix 
\[ A(C_{2n})=\begin{bmatrix}0 & B \\ B^T & 0\end{bmatrix} \]
where \(B\in\R^{n\times n}\) \textit{e.g.}
\[B = \begin{bmatrix}1&0&0&0&1 \\ 1&1&0&0&0 \\ 0&1&1&0&0 \\ 0&0&1&1&0 \\ 0&0&0&1&1 \end{bmatrix}\in\R^{5\times 5} \]
We can verify that
\[ B^T B=2I_n+\underbrace{A(C_n)}_{\begin{bmatrix}0&1&0&0&1 \\ 1&0&1&0&0 \\ 0&1&0&1&0 \\ 0&0&1&0&1 \\ 1&0&0&1&0 \end{bmatrix}} \]
Therefore if \(\lambda_1,\cdots,\lambda_n\) are the eigenvalues of \(C_n\), then the eigenvalues of \(C_{2n}\) are
\[ \pm\sqrt{2+\lambda_k}, \quad k=1,\cdots,n \]
This agrees with our early calculations
 \[ \lambda_k=2\cos\left(\frac{2\pi k}{n} \right) \]
with identity
\[ 1+\cos(2\theta)=2\cos^2\theta \]
\end{example}


\begin{corollary}
If \(G\) is bipartite graph on \(n\) vertices then \(\lambda_n(G)=-\lambda_1(G)\).
\end{corollary}
\begin{remark}
A converse holds for connected graphs.
\end{remark}
\begin{proposition}
If \(G\) is connected on \(n\) vertices and \(\lambda_n(G)=-\lambda_1(G)\), then \(G\) is bipartite.
\end{proposition}
\begin{remark}
It's another consequence of the Perron-Frobenius theorem. We don't prove this.
\end{remark}



\section{Cartesian Products}

\begin{definition}[Cartesian product]
Let \(G\) and \(H\) be graphs, the \emph{Cartesian product} \(G\square H\) has vertex set \(V(G)\times V(H)\) with edges of the forms
\begin{itemize}
\item \((v,w)\sim(v',w)\) where \(v\sim v'\) in \(G\) and \(w\in V(H)\)
\item \((v,w)\sim(v,w')\) where \(w\sim w'\) in \(H\) and \(v\in V(G)\)
\end{itemize}
\end{definition}

\begin{example}
\(P_m\square P_n\) is the \(m\times n\) rectangular lattice.
\(P_2\square P_2\square P_2\) is the 1-skeleton of cube.
In general, \(\underbrace{P_2\square\cdots\square P_2}_{n\text{ copies}}\) is the 1-skeleton of the \(n\)-dimensional hypercube \([0,1]^n\subset\R^{n}\)
\end{example}
\begin{remark}
Cartesian product is associative.
\end{remark}

\begin{definition}[Tensor product]
Let \(\R^m\otimes\R^n\) denote the tensor product of \(\R^m\) and \(\R^n\) which we will identify with the vector space of matrices \(\R^{m\times n}\).
Let \(e^{(i)}\) denote the unit vector (\(i^\text{th}\) entry is one and zeros elsewhere) and define the standard basis of \(\R^{m\times n}\):
\[ \left\{ e^{(i)}e^{(j)T}=\kbordermatrix{ &  &  & j &  & \\  & 0 & 0 & 0 & 0 & 0 \\  & 0 & 0 & 0 & 0 & 0 \\ i & 0 & 0 & 1 & 0 & 0 \\ & 0 & 0 & 0 & 0 & 0 \\ & 0 & 0 & 0 & 0 & 0}, 1\leq i\leq m,1\leq j\leq n \right\} \]
For \(A\in\R^{m\times m},B\in\R^{n\times n}\), let \(A\otimes B\) denote the endomorphism of \(\R^{m\times n}\) given by
\[ (A\otimes B)(M)\coloneqq AMB^T \quad \text{for } M\in\R^{m\times n}. \]
\end{definition}

\begin{lemma}
Let two matrices \(A\in\R^{m\times m},B\in\R^{n\times n}\), then
\[ (A\otimes B)_{(i,j),(k,l)}=A_{i,k}B_{j,l}, \quad (1\leq i,k\leq m,1\leq j,l\leq n) \]
\end{lemma}
\begin{proof}
Recall that the entries of a matrix \(M\in\R^{d\times d}\) are characterized by
\[ Me^{(j)}=\sum_{i=1}^{d}M_{i,j}e^{(i)} \quad \text{for } 1\leq j\leq d. \]
\begin{align*}
(A\otimes B)\left(e^{(k)}e^{(l)T}\right)&=A\left(e^{(k)}e^{(l)T}\right)B^T\\
&=\left(Ae^{(k)}\right)\left(Be^{(l)}\right)^T\\
&=\left(\sum_{i=1}^m A_{i,k}e^{(i)}\right)\left(\sum_{j=1}^n B_{j,l}e^{(j)}\right)^T\\
&=\sum_{i=1}^m \sum_{j=1}^n A_{i,k}B_{j,l} e^{(i)}e^{(j)T}
\end{align*}
\end{proof}

\begin{corollary}
Let \(G\) and \(H\) be graphs with basis of eigenvectors \(x^{(1)},\cdots,x^{(m)}\in\R^m\) and \(y^{(1)},\cdots,y^{(n)}\in\R^n\) corresponding to eigenvalues \(\lambda_1,\cdots,\lambda_m\) and \(\mu_1,\cdots,\mu_n\), then
\[ A(G\square H)=A(G)\otimes I_n + I_m\otimes A(H) \]
and \(G\square H\) has eigenvectors \(x^{(i)}y^{(j)T}\) corresponding to eigenvalues \(\lambda_i+\mu_j\) for \(1\leq i \leq m,1\leq j\leq n\).
\end{corollary}
\begin{remark}
Note that \(\left\{x^{(i)}y^{(j)T}\right\}\) forms a basis of \(\R^{m\times n}\) since they are the unit matrices (matrices with a 1 and 0's elsewhere) under the basis \(x^{(1)},\cdots,x^{(m)}\) of \(\R^m\) and the basis dual to \(y^{(1)},\cdots,y^{(n)}\in\R^n\).
(If \(y^{(1)},\cdots,y^{(n)}\in\R^n\) are orthonormal, it's self-dual).
\end{remark}